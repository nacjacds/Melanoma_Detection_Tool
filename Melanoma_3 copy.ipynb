{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Configuración de rutas\n",
    "base_dir = 'data'  # Reemplaza con la ruta principal donde están train, test, valid\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "# Generador de datos con normalización y aumento ajustado para el entrenamiento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,  # Reducir rotación\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # Añadir flips verticales si es necesario\n",
    "    brightness_range=[0.9, 1.1],  # Reducir el rango de brillo\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Crear los generadores\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = valid_test_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Mantener False para evitar desalineación\n",
    ")\n",
    "# Seleccionar y cargar el modelo preentrenado\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Cargar el modelo base\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Descongelar las últimas capas del modelo base DenseNet121\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:  # Descongelar solo las últimas 50 capas\n",
    "    layer.trainable = False\n",
    "# Añadir capas superiores personalizadas con regularización L2 y Dropout adicional\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.005))(x)  # Solo regularización L2\n",
    "x = layers.Dropout(0.5)(x)  # Mantener Dropout para evitar sobreajuste\n",
    "outputs = layers.Dense(2, activation='softmax')(x)  # Suponiendo 2 clases: Melanoma y NotMelanoma\n",
    "\n",
    "# Crear el modelo completo\n",
    "model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compilar el modelo con tasa de aprendizaje inicial ajustada\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),  # Comenzar con una tasa de aprendizaje más alta\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', AUC(name='auc')])  # Añadir la métrica AUC\n",
    "\n",
    "# Mostrar la arquitectura del modelo\n",
    "model.summary()\n",
    "\n",
    "# Configurar los pasos por época basados en el tamaño de datos y batch size\n",
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
    "\n",
    "# Guardar el mejor modelo durante el entrenamiento\n",
    "checkpoint_path = 'models/best_melanomaornot_model_02.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_auc',  # Monitorear AUC en lugar de val_loss\n",
    "                             mode='max',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "\n",
    "# Parar temprano si no hay mejora\n",
    "early_stopping = EarlyStopping(monitor='val_auc', patience=5, verbose=1, restore_best_weights=True, mode='max')\n",
    "\n",
    "# Reducir la tasa de aprendizaje si no hay mejora\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=2, verbose=1, min_lr=1e-7, mode='max')\n",
    "# Registrar el historial de entrenamiento para reanudarlo en caso de interrupción\n",
    "csv_logger = CSVLogger('training_log.csv', append=True)\n",
    "\n",
    "# Callback personalizado para calcular AUC-ROC en cada época\n",
    "class RocAucCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_pred = self.model.predict(validation_generator)\n",
    "        val_true = validation_generator.classes\n",
    "        auc = roc_auc_score(val_true, val_pred[:, 1])\n",
    "        print(f'Epoch {epoch + 1} - val_auc: {auc:.4f}')\n",
    "\n",
    "# Calcular los pesos de las clases basado en el número de muestras\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "# Cargar el modelo existente si hay un checkpoint guardado\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "    print(f\"Modelo cargado desde {checkpoint_path}\")\n",
    "# Entrenar el modelo con el cálculo de AUC-ROC y class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr, csv_logger, RocAucCallback()],\n",
    "    class_weight=dict(enumerate(class_weights))  # Añadir class_weight para manejar el desbalance\n",
    ")\n",
    "# Evaluar el modelo en el conjunto de pruebas\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Calcular el número de steps exactos para cubrir todas las muestras\n",
    "steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "\n",
    "# Calcular las predicciones con el número de steps correcto\n",
    "predictions = model.predict(test_generator, steps=steps, verbose=1)\n",
    "\n",
    "# Asegúrate de que no falten imágenes al final del proceso\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Comparar las longitudes de true_classes y predicted_classes\n",
    "true_classes = test_generator.classes\n",
    "assert len(true_classes) == len(predicted_classes), \"Mismatch in number of predictions and true labels\"\n",
    "\n",
    "# Calcular AUC-ROC\n",
    "auc = roc_auc_score(true_classes, predictions[:, 1])  # Suponiendo que la clase positiva es la segunda columna\n",
    "print(f'AUC-ROC: {auc:.2f}')\n",
    "\n",
    "# Imprimir el tamaño de la salida de predicciones\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Predicted classes length: {len(predicted_classes)}\")\n",
    "print(f\"True classes length: {len(true_classes)}\")\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "if len(true_classes) == len(predicted_classes):\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "    print(report)\n",
    "else:\n",
    "    print(\"Las longitudes de true_classes y predicted_classes no coinciden. No se puede generar el reporte.\")\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Guardar el modelo actualizado\n",
    "model.save('models/melanoma_3.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
