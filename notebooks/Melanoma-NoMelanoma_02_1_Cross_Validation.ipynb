{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 00:27:40.245641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import clone_model\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resized images\n",
    "train_dir = '../data/train' \n",
    "valid_dir = '../data/valid'\n",
    "test_dir = '../data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10682 images belonging to 2 classes.\n",
      "Found 3561 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generador de datos con normalización y aumentación solo para el entrenamiento, esto ayuda a generalizar mejor.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Crear los generadores\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = valid_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar y cargar el modelo preentrenado\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Cambiar este valor para probar diferentes modelos\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear listas para almacenar las imágenes y etiquetas\n",
    "X, y = [], []\n",
    "\n",
    "# Iterar sobre el generador de entrenamiento y extraer las imágenes y etiquetas\n",
    "for _ in range(len(train_generator)):\n",
    "    X_batch, y_batch = next(train_generator)\n",
    "    X.append(X_batch)\n",
    "    y.append(y_batch)\n",
    "\n",
    "# Convertir las listas a arrays numpy\n",
    "X = np.vstack(X)\n",
    "y = np.vstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1352s\u001b[0m 5s/step - accuracy: 0.5044 - loss: 1.2191 - val_accuracy: 0.5512 - val_loss: 0.9009 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1432s\u001b[0m 5s/step - accuracy: 0.5698 - loss: 0.8519 - val_accuracy: 0.6430 - val_loss: 0.7551 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1307s\u001b[0m 5s/step - accuracy: 0.6193 - loss: 0.7410 - val_accuracy: 0.6439 - val_loss: 0.7111 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1184s\u001b[0m 4s/step - accuracy: 0.6351 - loss: 0.7069 - val_accuracy: 0.6378 - val_loss: 0.6943 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 4s/step - accuracy: 0.6378 - loss: 0.6920 - val_accuracy: 0.6397 - val_loss: 0.6840 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 4s/step - accuracy: 0.6387 - loss: 0.6841 - val_accuracy: 0.6420 - val_loss: 0.6761 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 4s/step - accuracy: 0.6473 - loss: 0.6751 - val_accuracy: 0.6425 - val_loss: 0.6695 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1035s\u001b[0m 4s/step - accuracy: 0.6408 - loss: 0.6690 - val_accuracy: 0.6500 - val_loss: 0.6632 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1184s\u001b[0m 4s/step - accuracy: 0.6449 - loss: 0.6630 - val_accuracy: 0.6462 - val_loss: 0.6594 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1084s\u001b[0m 4s/step - accuracy: 0.6528 - loss: 0.6575 - val_accuracy: 0.6430 - val_loss: 0.6564 - learning_rate: 1.0000e-04\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 4s/step - accuracy: 0.6236 - loss: 0.6611\n",
      "Epoch 1/10\n",
      "\u001b[1m 26/268\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15:12\u001b[0m 34s/step - accuracy: 0.5136 - loss: 1.3569"
     ]
    }
   ],
   "source": [
    "# Definir el número de splits para la validación cruzada\n",
    "n_splits = 5\n",
    "\n",
    "# Crear los objetos de validación cruzada\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Guardar las métricas para cada fold\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X, np.argmax(y, axis=1)):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Clonar el modelo original\n",
    "    model = clone_model(base_model)\n",
    "    model.trainable = False\n",
    "    \n",
    "    # Añadir capas superiores personalizadas\n",
    "    x = model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(2, activation='softmax')(x)  # Suponiendo 2 clases: Melanoma y NotMelanoma\n",
    "    \n",
    "    model = models.Model(inputs=model.input, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Definir callbacks\n",
    "    checkpoint = ModelCheckpoint(f'best_model_fold_{len(accuracy_scores)+1}.keras', monitor='val_loss', save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo en el fold actual\n",
    "history = model.fit(X_train_fold, y_train_fold,\n",
    "                     validation_data=(X_val_fold, y_val_fold),\n",
    "                    epochs=10,  # Ajusta según sea necesario\n",
    "                    callbacks=[checkpoint, early_stopping, reduce_lr])\n",
    "    \n",
    "# Evaluar el modelo en el fold de validación\n",
    "val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "accuracy_scores.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular y mostrar la precisión promedio en los folds\n",
    "print(f\"Accuracy promedio en validación cruzada: {np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de pruebas\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de steps exactos para cubrir todas las muestras\n",
    "steps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "\n",
    "# Calcular las predicciones con el número de steps correcto\n",
    "predictions = model.predict(test_generator, steps=steps, verbose=1)\n",
    "\n",
    "# Asegurarme de que no falten imágenes al final del proceso\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el tamaño de la salida de predicciones\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Predicted classes length: {len(predicted_classes)}\")\n",
    "true_classes = test_generator.classes\n",
    "print(f\"True classes length: {len(true_classes)}\")\n",
    "\n",
    "# Comparar las longitudes de true_classes y predicted_classes\n",
    "if len(true_classes) == len(predicted_classes):\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=['Melanoma', 'NotMelanoma'])\n",
    "    print(report)\n",
    "else:\n",
    "    print(\"Las longitudes de true_classes y predicted_classes no coinciden. No se puede generar el reporte.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
