{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "train_dir = 'model_evaluation/train'\n",
    "test_dir = 'model_evaluation/test'\n",
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15132 images belonging to 2 classes.\n",
      "Found 3932 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Crear generadores de datos con augmentación moderada\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Mantener aumentación moderada\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo preentrenado\n",
    "model = load_model('models/best_model_fold_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar la arquitectura del modelo para fine-tuning\n",
    "inputs = model.input\n",
    "x = model.layers[-2].output\n",
    "\n",
    "# Añadir Dropout si no está ya en el modelo\n",
    "if not any(isinstance(layer, layers.Dropout) for layer in model.layers):\n",
    "    x = layers.Dropout(0.3)(x)  # Ajustar el Dropout a un 30%\n",
    "\n",
    "# Añadir la nueva capa Dense con regularización L2\n",
    "x = layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "\n",
    "# Crear el nuevo modelo\n",
    "model = models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Configurar el optimizador con un learning rate fijo\n",
    "initial_learning_rate = 5e-5  # Ajustar según sea necesario\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)  # Fijo, no LearningRateSchedule\n",
    "\n",
    "# Compilar el modelo con pérdida binaria y el nuevo optimizador\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de las clases calculados: {0: 2.0465242088179605, 1: 0.6616528202885876}\n"
     ]
    }
   ],
   "source": [
    "# Obtener el índice de las clases desde el generador\n",
    "melanoma_index = train_generator.class_indices['Melanoma']\n",
    "not_melanoma_index = train_generator.class_indices['NotMelanoma']\n",
    "\n",
    "# Contar el número de imágenes en cada clase\n",
    "melanoma_count = np.sum(train_generator.classes == melanoma_index)\n",
    "not_melanoma_count = np.sum(train_generator.classes == not_melanoma_index)\n",
    "total_images = melanoma_count + not_melanoma_count\n",
    "\n",
    "# Calcular los pesos de las clases\n",
    "class_weights = {\n",
    "    melanoma_index: total_images / (2 * melanoma_count),  # Peso para Melanoma\n",
    "    not_melanoma_index: total_images / (2 * not_melanoma_count)  # Peso para NotMelanoma\n",
    "}\n",
    "\n",
    "print(f\"Pesos de las clases calculados: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de las imágenes: (32, 224, 224, 3)\n",
      "Tamaño de las etiquetas: (32,)\n"
     ]
    }
   ],
   "source": [
    "# Verificar un batch del generador de entrenamiento\n",
    "images, labels = next(train_generator)\n",
    "print(f\"Tamaño de las imágenes: {images.shape}\")\n",
    "print(f\"Tamaño de las etiquetas: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar los callbacks\n",
    "checkpoint = callbacks.ModelCheckpoint(\"fine_tuned_model.weights.h5\", monitor='val_loss', save_best_only=True, mode='min', save_weights_only=True)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Callback adicional para respaldos de pesos\n",
    "class BackupCheckpoint(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Validar logs y evitar errores si es None\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        # Guardar los pesos del modelo como backup\n",
    "        self.model.save_weights(f\"backup_epoch_{epoch+1}.weights.h5\")\n",
    "\n",
    "backup_checkpoint = BackupCheckpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/70\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ajusta este valor al último epoch completado\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackup_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/trainer.py:931\u001b[0m, in \u001b[0;36mTrainer._pythonify_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pythonify_logs\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs):\n\u001b[1;32m    930\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    933\u001b[0m             result\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=70,\n",
    "    initial_epoch=48,  # Ajusta este valor al último epoch completado\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr, backup_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo después del entrenamiento\n",
    "model.save('fine_tuned_model_final.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 4s/step - accuracy: 0.4612 - loss: 0.7768\n",
      "Test Loss: 0.7556\n",
      "Test Accuracy: 75.05%\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "evaluation = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {evaluation[0]:.4f}')\n",
    "print(f'Test Accuracy: {evaluation[1]*100:.2f}%')\n",
    "\n",
    "# Obtener predicciones para cada imagen en el conjunto de prueba\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "true_classes = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el informe de clasificación\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Mostrar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Añadir los números en la matriz de confusión\n",
    "for i in range(len(class_labels)):\n",
    "    for j in range(len(class_labels)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), ha='center', va='center', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLICACIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "Carga del Modelo Preentrenado: El modelo se carga desde models/best_model_fold_2.keras.\n",
    "\n",
    "Ajuste del Modelo:\n",
    "\n",
    "Se verifica la última capa del modelo y se ajusta para clasificación binaria si es necesario.\n",
    "Se añade Dropout después de las capas densas si no estaba presente.\n",
    "Compilación y Entrenamiento: El modelo se recompila y se entrena con los datos nuevos de train_dir y test_dir.\n",
    "\n",
    "Respaldo: Se incluye un callback personalizado para guardar los pesos después de cada época (backup_checkpoint).\n",
    "\n",
    "Resumen:\n",
    "Este código te permitirá hacer fine-tuning sobre el modelo que ya entrenaste, utilizando las nuevas imágenes y ajustando el modelo para manejar el desbalanceo de clases. Además, asegura que no perderás el progreso si el entrenamiento se interrumpe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estrategia propuesta es sólida y está bien encaminada, pero podemos considerar algunos puntos para maximizar su efectividad. Aquí hay algunas consideraciones que podrías evaluar para asegurarte de que la estrategia sea la mejor:\n",
    "\n",
    "1. Carga del Modelo Preentrenado y Fine-Tuning:\n",
    "Pros: Aprovechas un modelo ya entrenado y bien ajustado, lo que debería acelerar el proceso de convergencia y mejorar la precisión en el nuevo conjunto de datos.\n",
    "Cons: Si el modelo original estaba sobreajustado (overfitted) al conjunto de datos original, podría tener problemas para generalizar en los nuevos datos, incluso con el fine-tuning. En este caso, ajustar la estructura del modelo (añadir regularización o Dropout) es esencial.\n",
    "2. Manejo del Desbalance de Clases:\n",
    "Pros: Usar ponderación de clases es una estrategia común y efectiva para manejar el desbalance en los datos, especialmente en problemas binarios como este.\n",
    "Cons: Aunque ponderar las clases ayuda, puede ser complementado con técnicas de aumentación de datos para la clase minoritaria, o incluso con técnicas más avanzadas como Oversampling (SMOTE) en el espacio de los datos de entrenamiento.\n",
    "3. Regularización y Dropout:\n",
    "Pros: Agregar regularización y Dropout es una buena estrategia para prevenir el sobreajuste, especialmente cuando el nuevo conjunto de datos es más grande y diverso.\n",
    "Cons: La cantidad de Dropout debe ser ajustada cuidadosamente; demasiado Dropout puede reducir la capacidad de aprendizaje del modelo, mientras que demasiado poco puede no ser suficiente para prevenir el sobreajuste.\n",
    "4. Verificación de Progreso y Backup de Pesos:\n",
    "Pros: Implementar un backup regular de los pesos garantiza que no se pierda el progreso en caso de interrupciones.\n",
    "Cons: Asegúrate de monitorizar los pesos guardados para evitar guardar un modelo que se esté sobreajustando, lo que podría suceder si el proceso se reanuda muchas veces.\n",
    "5. Monitoreo de Métricas de Validación:\n",
    "Pros: El uso de callbacks como EarlyStopping y ReduceLROnPlateau es excelente para ajustar dinámicamente el aprendizaje y evitar sobreajuste.\n",
    "Cons: Es vital monitorizar no solo la pérdida (loss) sino también la precisión (accuracy) y otras métricas como la f1-score, especialmente en casos de desbalance de clases.\n",
    "6. Ajuste Final del Modelo:\n",
    "Pros: Cargar el mejor modelo basado en la validación cruzada y luego hacer fine-tuning con datos adicionales puede consolidar el rendimiento.\n",
    "Cons: Después del fine-tuning, es crucial validar nuevamente el modelo con un conjunto de datos completamente nuevo o realizar una validación cruzada adicional.\n",
    "Conclusión:\n",
    "Esta estrategia es sólida, pero tiene algunos aspectos que pueden ser optimizados o ajustados según los resultados que vayas observando en cada paso. La clave es asegurarse de que el modelo no se sobreajuste y de que las métricas reflejen una buena generalización a datos no vistos. Además, mantener un enfoque iterativo, ajustando parámetros según sea necesario, te permitirá obtener los mejores resultados posibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
